# Generated from Enquestes.g by ANTLR 4.7.1
from antlr4 import *
from io import StringIO
from typing.io import TextIO
import sys


def serializedATN():
    with StringIO() as buf:
        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\2\23")
        buf.write("{\b\1\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7")
        buf.write("\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4\f\t\f\4\r\t\r\4\16")
        buf.write("\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22\3\2\3\2")
        buf.write("\3\2\3\2\3\2\3\2\3\2\3\2\3\2\3\3\3\3\3\3\3\3\3\3\3\3\3")
        buf.write("\3\3\3\3\3\3\4\3\4\3\4\3\4\3\4\3\4\3\4\3\4\3\4\3\5\3\5")
        buf.write("\3\5\3\5\3\5\3\5\3\5\3\5\3\5\3\5\3\5\3\5\3\6\3\6\3\6\3")
        buf.write("\6\3\6\3\7\3\7\3\7\3\7\3\b\6\bW\n\b\r\b\16\bX\3\b\3\b")
        buf.write("\7\b]\n\b\f\b\16\b`\13\b\3\t\3\t\3\n\3\n\3\13\3\13\3\13")
        buf.write("\3\f\3\f\3\r\3\r\3\16\3\16\3\17\3\17\3\20\3\20\3\21\3")
        buf.write("\21\3\22\6\22v\n\22\r\22\16\22w\3\22\3\22\2\2\23\3\3\5")
        buf.write("\4\7\5\t\6\13\7\r\b\17\t\21\n\23\13\25\f\27\r\31\16\33")
        buf.write("\17\35\20\37\21!\22#\23\3\2\4\6\2\62;C\\c|\u0082\u0101")
        buf.write("\4\2\f\f\"\"\2}\2\3\3\2\2\2\2\5\3\2\2\2\2\7\3\2\2\2\2")
        buf.write("\t\3\2\2\2\2\13\3\2\2\2\2\r\3\2\2\2\2\17\3\2\2\2\2\21")
        buf.write("\3\2\2\2\2\23\3\2\2\2\2\25\3\2\2\2\2\27\3\2\2\2\2\31\3")
        buf.write("\2\2\2\2\33\3\2\2\2\2\35\3\2\2\2\2\37\3\2\2\2\2!\3\2\2")
        buf.write("\2\2#\3\2\2\2\3%\3\2\2\2\5.\3\2\2\2\7\67\3\2\2\2\t@\3")
        buf.write("\2\2\2\13L\3\2\2\2\rQ\3\2\2\2\17V\3\2\2\2\21a\3\2\2\2")
        buf.write("\23c\3\2\2\2\25e\3\2\2\2\27h\3\2\2\2\31j\3\2\2\2\33l\3")
        buf.write("\2\2\2\35n\3\2\2\2\37p\3\2\2\2!r\3\2\2\2#u\3\2\2\2%&\7")
        buf.write("R\2\2&\'\7T\2\2\'(\7G\2\2()\7I\2\2)*\7W\2\2*+\7P\2\2+")
        buf.write(",\7V\2\2,-\7C\2\2-\4\3\2\2\2./\7T\2\2/\60\7G\2\2\60\61")
        buf.write("\7U\2\2\61\62\7R\2\2\62\63\7Q\2\2\63\64\7U\2\2\64\65\7")
        buf.write("V\2\2\65\66\7C\2\2\66\6\3\2\2\2\678\7G\2\289\7P\2\29:")
        buf.write("\7S\2\2:;\7W\2\2;<\7G\2\2<=\7U\2\2=>\7V\2\2>?\7C\2\2?")
        buf.write("\b\3\2\2\2@A\7C\2\2AB\7N\2\2BC\7V\2\2CD\7G\2\2DE\7T\2")
        buf.write("\2EF\7P\2\2FG\7C\2\2GH\7V\2\2HI\7K\2\2IJ\7X\2\2JK\7C\2")
        buf.write("\2K\n\3\2\2\2LM\7K\2\2MN\7V\2\2NO\7G\2\2OP\7O\2\2P\f\3")
        buf.write("\2\2\2QR\7G\2\2RS\7P\2\2ST\7F\2\2T\16\3\2\2\2UW\t\2\2")
        buf.write("\2VU\3\2\2\2WX\3\2\2\2XV\3\2\2\2XY\3\2\2\2Y^\3\2\2\2Z")
        buf.write("[\7\"\2\2[]\5\17\b\2\\Z\3\2\2\2]`\3\2\2\2^\\\3\2\2\2^")
        buf.write("_\3\2\2\2_\20\3\2\2\2`^\3\2\2\2ab\7<\2\2b\22\3\2\2\2c")
        buf.write("d\7A\2\2d\24\3\2\2\2ef\7/\2\2fg\7@\2\2g\26\3\2\2\2hi\7")
        buf.write("=\2\2i\30\3\2\2\2jk\7*\2\2k\32\3\2\2\2lm\7+\2\2m\34\3")
        buf.write("\2\2\2no\7.\2\2o\36\3\2\2\2pq\7_\2\2q \3\2\2\2rs\7]\2")
        buf.write("\2s\"\3\2\2\2tv\t\3\2\2ut\3\2\2\2vw\3\2\2\2wu\3\2\2\2")
        buf.write("wx\3\2\2\2xy\3\2\2\2yz\b\22\2\2z$\3\2\2\2\6\2X^w\3\b\2")
        buf.write("\2")
        return buf.getvalue()


class EnquestesLexer(Lexer):

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    PREGUNTA = 1
    RESPOSTA = 2
    ENQUESTA = 3
    ALTERNATIVA = 4
    ITEM = 5
    END = 6
    PARAULA = 7
    DOS_PUNTS = 8
    INTERROGACIO = 9
    FLETXA = 10
    PUNT_COMA = 11
    L_P = 12
    R_P = 13
    COMA = 14
    R_B = 15
    L_B = 16
    WS = 17

    channelNames = [ u"DEFAULT_TOKEN_CHANNEL", u"HIDDEN" ]

    modeNames = [ "DEFAULT_MODE" ]

    literalNames = [ "<INVALID>",
            "'PREGUNTA'", "'RESPOSTA'", "'ENQUESTA'", "'ALTERNATIVA'", "'ITEM'", 
            "'END'", "':'", "'?'", "'->'", "';'", "'('", "')'", "','", "']'", 
            "'['" ]

    symbolicNames = [ "<INVALID>",
            "PREGUNTA", "RESPOSTA", "ENQUESTA", "ALTERNATIVA", "ITEM", "END", 
            "PARAULA", "DOS_PUNTS", "INTERROGACIO", "FLETXA", "PUNT_COMA", 
            "L_P", "R_P", "COMA", "R_B", "L_B", "WS" ]

    ruleNames = [ "PREGUNTA", "RESPOSTA", "ENQUESTA", "ALTERNATIVA", "ITEM", 
                  "END", "PARAULA", "DOS_PUNTS", "INTERROGACIO", "FLETXA", 
                  "PUNT_COMA", "L_P", "R_P", "COMA", "R_B", "L_B", "WS" ]

    grammarFileName = "Enquestes.g"

    def __init__(self, input=None, output:TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.7.1")
        self._interp = LexerATNSimulator(self, self.atn, self.decisionsToDFA, PredictionContextCache())
        self._actions = None
        self._predicates = None


